---
id: clusters
title: Clusters
sidebar_label: Clusters
sidebar_position: 8
description: This guide provides a comprehensive overview of Temporal Clusters.
slug: /clusters
toc_max_heading_level: 4
keywords:
- explanation
- term
tags:
- explanation
- term
---

<!-- THIS FILE IS GENERATED. DO NOT EDIT THIS FILE DIRECTLY -->

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

This guide provides a comprehensive overview of Temporal Clusters.

A Temporal Cluster is the group of services, known as the [Temporal Server](#temporal-server) <span id="i-c4910f29-3030-4e6d-915b-34f0e10b622d" class="clickable-i clickable-link-preview">ðŸ”—</span><div id="preview-modal-c4910f29-3030-4e6d-915b-34f0e10b622d" class="preview-modal"><div class="modal-header"><div id="x-c4910f29-3030-4e6d-915b-34f0e10b622d" class="clickable-x clickable-link-preview">x</div><b>Link preview</b></div><div class="preview-modal-title">What is the Temporal Server?</div><div class="preview-modal-description">The Temporal Server is a grouping of four horizontally scalable services.</div><div class="preview-modal-tags"><span class="preview-modal-tag">term</span> <span class="preview-modal-tag">explanation</span></div></div>, combined with [Persistence](#persistence) <span id="i-2734bd42-566a-47aa-9456-beded8ca2768" class="clickable-i clickable-link-preview">ðŸ”—</span><div id="preview-modal-2734bd42-566a-47aa-9456-beded8ca2768" class="preview-modal"><div class="modal-header"><div id="x-2734bd42-566a-47aa-9456-beded8ca2768" class="clickable-x clickable-link-preview">x</div><b>Link preview</b></div><div class="preview-modal-title">What is Persistence?</div><div class="preview-modal-description">The Temporal Persistence store is a database used by Temporal Services to persist events generated and processed in the Temporal Cluster and SDK.</div><div class="preview-modal-tags"><span class="preview-modal-tag">term</span> <span class="preview-modal-tag">explanation</span></div></div> and [Visibility](#visibility) <span id="i-879e0193-4d8d-4ed8-ab3b-7edc4b32e2a6" class="clickable-i clickable-link-preview">ðŸ”—</span><div id="preview-modal-879e0193-4d8d-4ed8-ab3b-7edc4b32e2a6" class="preview-modal"><div class="modal-header"><div id="x-879e0193-4d8d-4ed8-ab3b-7edc4b32e2a6" class="clickable-x clickable-link-preview">x</div><b>Link preview</b></div><div class="preview-modal-title">What is Visibility?</div><div class="preview-modal-description">The term Visibility, within the Temporal Platform, refers to the subsystems and APIs that enable an operator to view Workflow Executions that currently exist within a Cluster.</div><div class="preview-modal-tags"><span class="preview-modal-tag">term</span></div></div> stores, that together act as a component of the Temporal Platform.

- [How to quickly install a Temporal Cluster for testing and development](/kb/all-the-ways-to-run-a-cluster)
- [Cluster deployment guide](/cluster-deployment-guide)

![A Temporal Cluster (Server + persistence)](/diagrams/temporal-cluster.svg)

<!-- ### Visibility
Commenting this out because it is out of place. Using the what is visibility concept topic in the guide instead.
Also these details are covered in the Visibility store setup under cluster deployment.

Temporal has built-in [Visibility](#visibility) <span id="i-b53646ee-15d0-4e0e-aa0a-aaa9729da6c8" class="clickable-i clickable-link-preview">ðŸ”—</span><div id="preview-modal-b53646ee-15d0-4e0e-aa0a-aaa9729da6c8" class="preview-modal"><div class="modal-header"><div id="x-b53646ee-15d0-4e0e-aa0a-aaa9729da6c8" class="clickable-x clickable-link-preview">x</div><b>Link preview</b></div><div class="preview-modal-title">What is Visibility?</div><div class="preview-modal-description">The term Visibility, within the Temporal Platform, refers to the subsystems and APIs that enable an operator to view Workflow Executions that currently exist within a Cluster.</div><div class="preview-modal-tags"><span class="preview-modal-tag">term</span></div></div> features.
To enhance this feature, Temporal supports an [integration with Elasticsearch](/cluster-deployment-guide#elasticsearch) <span id="i-79c8dea9-9b15-4094-a8c4-55e16119d285" class="clickable-i clickable-link-preview">ðŸ”—</span><div id="preview-modal-79c8dea9-9b15-4094-a8c4-55e16119d285" class="preview-modal"><div class="modal-header"><div id="x-79c8dea9-9b15-4094-a8c4-55e16119d285" class="clickable-x clickable-link-preview">x</div><b>Link preview</b></div><div class="preview-modal-title">How to integrate Elasticsearch into a Temporal Cluster</div><div class="preview-modal-description">To integrate Elasticsearch with your Temporal Cluster, edit the `persistence` section of your `development.yaml` configuration file and run the index schema setup commands.</div><div class="preview-modal-tags"><span class="preview-modal-tag">operation-guide</span> <span class="preview-modal-tag">filtered-lists</span> <span class="preview-modal-tag">visibility</span></div></div>.

- Elasticsearch v8 is supported from Temporal version 1.18.0 onwards
- Elasticsearch v7.10 is supported from Temporal version 1.7.0 onwards
- Elasticsearch v6.8 is supported up to Temporal version 1.17.x
- Elasticsearch v6.8 and v7.10 versions are explicitly supported with AWS Elasticsearch -->

## What is the Temporal Server? {#temporal-server}

The Temporal Server consists of four independently scalable services:

- Frontend gateway: for rate limiting, routing, authorizing.
- History subsystem: maintains data (mutable state, queues, and timers).
- Matching subsystem: hosts Task Queues for dispatching.
- Worker Service: for internal background Workflows.

For example, a real-life production deployment can have 5 Frontend, 15 History, 17 Matching, and 3 Worker Services per cluster.

The Temporal Server services can run independently or be grouped together into shared processes on one or more physical or virtual machines.
For live (production) environments, we recommend that each service runs independently, because each one has different scaling requirements and troubleshooting becomes easier.
The History, Matching, and Worker Services can scale horizontally within a Cluster.
The Frontend Service scales differently than the others because it has no sharding or partitioning; it is just stateless.

Each service is aware of the others, including scaled instances, through a membership protocol via [Ringpop](https://github.com/temporalio/ringpop-go).

#### Versions and support

All Temporal Server releases abide by the [Semantic Versioning Specification](https://semver.org/).

We support upgrade paths from every version beginning with Temporal v1.7.0.
For details on upgrading your Temporal Cluster, see [Upgrade Server](/cluster-deployment-guide#upgrade-server).

We provide maintenance support for previously published minor and major versions by continuing to release critical bug fixes related to security, the prevention of data loss, and reliability, whenever they are found.

We aim to publish incremental upgrade guides for each minor and major version, which include specifics about dependency upgrades that we have tested for (such as Cassandra 3.0 -> 3.11).

We offer maintenance support of the last three **minor** versions after a release and do not plan to "backport" patches beyond that.

We offer maintenance support of **major** versions for at least 12 months after a GA release, and we provide at least 6 months' notice before EOL/deprecating support.

**Dependencies**

Temporal offers official support for, and is tested against, dependencies with the exact versions described in the `go.mod` file of the corresponding release tag.
(For example, [v1.5.1](https://github.com/temporalio/temporal/tree/v1.5.1) dependencies are documented in [the go.mod for v1.5.1](https://github.com/temporalio/temporal/blob/v1.5.1/go.mod).)

### What is a Frontend Service? {#frontend-service}

The Frontend Service is a stateless gateway service that exposes a strongly typed [Proto API](https://github.com/temporalio/api/blob/master/temporal/api/workflowservice/v1/service.proto).
The Frontend Service is responsible for rate limiting, authorizing, validating, and routing all inbound calls.

<div class="tdiw"><div class="tditw"><p class="tdit">Frontend Service</p></div><div class="tdiiw"><img class="img_ev3q" src="/diagrams/temporal-frontend-service.svg" alt="Frontend Service" height="1040" width="1140" /></div></div>

Types of inbound calls include the following:

- [Namespace](/namespaces#) <span id="i-e748d40b-c854-47c6-850f-cb0a9029b412" class="clickable-i clickable-link-preview">ðŸ”—</span><div id="preview-modal-e748d40b-c854-47c6-850f-cb0a9029b412" class="preview-modal"><div class="modal-header"><div id="x-e748d40b-c854-47c6-850f-cb0a9029b412" class="clickable-x clickable-link-preview">x</div><b>Link preview</b></div><div class="preview-modal-title">What is a Namespace?</div><div class="preview-modal-description">A Namespace is a unit of isolation within the Temporal Platform</div><div class="preview-modal-tags"><span class="preview-modal-tag">term</span> <span class="preview-modal-tag">explanation</span></div></div> CRUD
- External events
- Worker polls
- [Visibility](#visibility) <span id="i-08a792ba-7d0f-4e44-bf84-2f91947fd58e" class="clickable-i clickable-link-preview">ðŸ”—</span><div id="preview-modal-08a792ba-7d0f-4e44-bf84-2f91947fd58e" class="preview-modal"><div class="modal-header"><div id="x-08a792ba-7d0f-4e44-bf84-2f91947fd58e" class="clickable-x clickable-link-preview">x</div><b>Link preview</b></div><div class="preview-modal-title">What is Visibility?</div><div class="preview-modal-description">The term Visibility, within the Temporal Platform, refers to the subsystems and APIs that enable an operator to view Workflow Executions that currently exist within a Cluster.</div><div class="preview-modal-tags"><span class="preview-modal-tag">term</span></div></div> requests
- [tctl](/tctl-v1) (the Temporal CLI) operations
- Calls from a remote Cluster related to [Multi-Cluster Replication](#multi-cluster-replication) <span id="i-2c246674-971a-4509-9d23-4f962635189d" class="clickable-i clickable-link-preview">ðŸ”—</span><div id="preview-modal-2c246674-971a-4509-9d23-4f962635189d" class="preview-modal"><div class="modal-header"><div id="x-2c246674-971a-4509-9d23-4f962635189d" class="clickable-x clickable-link-preview">x</div><b>Link preview</b></div><div class="preview-modal-title">What is Multi-Cluster Replication?</div><div class="preview-modal-description">Multi-Cluster Replication is a feature which asynchronously replicates Workflow Executions from active Clusters to other passive Clusters, for backup and state reconstruction.</div><div class="preview-modal-tags"><span class="preview-modal-tag">term</span> <span class="preview-modal-tag">explanation</span></div></div>

Every inbound request related to a Workflow Execution must have a Workflow Id, which is hashed for routing purposes.
The Frontend Service has access to the hash rings that maintain service membership information, including how many nodes (instances of each service) are in the Cluster.

Inbound call rate limiting is applied per host and per namespace.

The Frontend Service talks to the Matching Service, History Service, Worker Service, the database, and Elasticsearch (if in use).

- It uses the grpcPort 7233 to host the service handler.
- It uses port 6933 for membership-related communication.

Ports are configurable in the Cluster configuration.

### What is a History Service? {#history-service}

The History Service is responsible for persisting Workflow Execution state to the Workflow History.
When the Workflow Execution is able to progress, the History Service adds a Task with the Workflow's updated history to the Task Queue.
From there, a Worker can poll for work, receive this updated history, and resume execution.

<div class="tdiw"><div class="tditw"><p class="tdit">Block diagram of how the History Service relates to the other services of the Temporal Server and to a Temporal Cluster</p></div><div class="tdiiw"><img class="img_ev3q" src="/diagrams/temporal-history-service.svg" alt="Block diagram of how the History Service relates to the other services of the Temporal Server and to a Temporal Cluster" height="1040" width="1140" /></div></div>

The total number of History Service processes can be between 1 and the total number of [History Shards](#history-shard) <span id="i-c47267e2-3b3a-4a56-b93d-c1a8a2d2c277" class="clickable-i clickable-link-preview">ðŸ”—</span><div id="preview-modal-c47267e2-3b3a-4a56-b93d-c1a8a2d2c277" class="preview-modal"><div class="modal-header"><div id="x-c47267e2-3b3a-4a56-b93d-c1a8a2d2c277" class="clickable-x clickable-link-preview">x</div><b>Link preview</b></div><div class="preview-modal-title">What is a History Shard?</div><div class="preview-modal-description">A History Shard is an important unit within a Temporal Cluster by which the scale of concurrent Workflow Execution throughput can be measured.</div><div class="preview-modal-tags"><span class="preview-modal-tag">term</span></div></div>.
An individual History Service can support many History Shards.
Temporal recommends starting at a ratio of 1 History Service process for every 500 History Shards.

Although the total number of History Shards remains static for the life of the Cluster, the number of History Service processess can change.

The History Service talks to the Matching Service and the database.

- It uses grpcPort 7234 to host the service handler.
- It uses port 6934 for membership-related communication.

Ports are configurable in the Cluster configuration.

#### What is a History Shard? {#history-shard}

A History Shard is an important unit within a Temporal Cluster by which concurrent Workflow Execution throughput can be scaled.

Each History Shard maps to a single persistence partition.
A History Shard assumes that only one concurrent operation can be within a partition at a time.
In essence, the number of History Shards represents the number of concurrent database operations that can occur for a Cluster.
This means that the number of History Shards in a Temporal Cluster plays a significant role in the performance of your Temporal Application.

Before integrating a database, the total number of History Shards for the Temporal Cluster must be chosen and set in the Cluster's configuration (see [persistence](/references/configuration#persistence) <span id="i-61f94592-c041-4049-b4c9-615bc5d80e2b" class="clickable-i clickable-link-preview">ðŸ”—</span><div id="preview-modal-61f94592-c041-4049-b4c9-615bc5d80e2b" class="preview-modal"><div class="modal-header"><div id="x-61f94592-c041-4049-b4c9-615bc5d80e2b" class="clickable-x clickable-link-preview">x</div><b>Link preview</b></div><div class="preview-modal-title">Temporal Cluster configuration reference</div><div class="preview-modal-description">Much of the behavior of a Temporal Cluster is configured using the `development.yaml` file.</div><div class="preview-modal-tags"><span class="preview-modal-tag">reference</span></div></div>).
After the Shard count is configured and the database integrated, the total number of History Shards for the Cluster cannot be changed.

In theory, a Temporal Cluster can operate with an unlimited number of History Shards, but each History Shard adds compute overhead to the Cluster.
Temporal Clusters have operated successfully using anywhere from 1 to 128K History Shards, with each Shard responsible for tens of thousands of Workflow Executions.
One Shard is useful only in small scale setups designed for testing, while 128k Shards is useful only in very large scale production environments.
The correct number of History Shards for any given Cluster depends entirely on the Temporal Application that it is supporting and the type of database.

A History Shard is represented as a hashed integer.
Each Workflow Execution is automatically assigned to a History Shard.
The assignment algorithm hashes Workflow Execution metadata such as Workflow Id and Namespace and uses that value to match a History Shard.

Each History Shard maintains the Workflow Execution Event History, Workflow Execution mutable state, and the following internal Task Queues:

- Internal Transfer Task Queue: Transfers internal tasks to the Matching Service.
  Whenever a new Workflow Task needs to be scheduled, the History Service's Transfer Task Queue Processor transactionally dispatches it to the Matching Service.
- Internal Timer Task Queue: Durably persists Timers.
- Internal Replicator Task Queue: Asynchronously replicates Workflow Executions from active Clusters to other passive Clusters.
  (Relies on the experimental Multi-Cluster feature.)
- Internal Visibility Task Queue: Pushes data to the [Advanced Visibility](/visibility#advanced-visibility) <span id="i-dbbb3eca-1dac-4751-9257-565335fa366d" class="clickable-i clickable-link-preview">ðŸ”—</span><div id="preview-modal-dbbb3eca-1dac-4751-9257-565335fa366d" class="preview-modal"><div class="modal-header"><div id="x-dbbb3eca-1dac-4751-9257-565335fa366d" class="clickable-x clickable-link-preview">x</div><b>Link preview</b></div><div class="preview-modal-title">What is advanced Visibility?</div><div class="preview-modal-description">Advanced Visibility, within the Temporal Platform, is the subsystem and APIs that enable the listing, filtering, and sorting of Workflow Executions through an SQL-like query syntax.</div><div class="preview-modal-tags"><span class="preview-modal-tag">explanation</span> <span class="preview-modal-tag">filtered-lists</span> <span class="preview-modal-tag">visibility</span></div></div> index.

### What is a Matching Service? {#matching-service}

The Matching Service is responsible for hosting user-facing [Task Queues](/workers#task-queue) <span id="i-cdef6fb3-dc23-494b-827b-c4438f1b8721" class="clickable-i clickable-link-preview">ðŸ”—</span><div id="preview-modal-cdef6fb3-dc23-494b-827b-c4438f1b8721" class="preview-modal"><div class="modal-header"><div id="x-cdef6fb3-dc23-494b-827b-c4438f1b8721" class="clickable-x clickable-link-preview">x</div><b>Link preview</b></div><div class="preview-modal-title">What is a Task Queue?</div><div class="preview-modal-description">A Task Queue is a first-in, first-out queue that a Worker Process polls for Tasks.</div><div class="preview-modal-tags"><span class="preview-modal-tag">term</span> <span class="preview-modal-tag">explanation</span></div></div> for Task dispatching.

<div class="tdiw"><div class="tditw"><p class="tdit">Matching Service</p></div><div class="tdiiw"><img class="img_ev3q" src="/diagrams/temporal-matching-service.svg" alt="Matching Service" height="980" width="870" /></div></div>

It is responsible for matching Workers to Tasks and routing new Tasks to the appropriate queue.
This service can scale internally by having multiple instances.

It talks to the Frontend Service, History Service, and the database.

- It uses grpcPort 7235 to host the service handler.
- It uses port 6935 for membership related communication.

Ports are configurable in the Cluster configuration.

### What is a Worker Service? {#worker-service}

The Worker Service runs background processing for the replication queue, system Workflows, and (in versions older than 1.5.0) the Kafka visibility processor.

<div class="tdiw"><div class="tditw"><p class="tdit">Worker Service</p></div><div class="tdiiw"><img class="img_ev3q" src="/diagrams/temporal-worker-service.svg" alt="Worker Service" height="740" width="1140" /></div></div>

It talks to the Frontend Service.

- It uses port 6939 for membership-related communication.

Ports are configurable in the Cluster configuration.

### What is a Retention Period? {#retention-period}

Retention Period is the duration for which the Temporal Cluster stores data associated with closed Workflow Executions on a Namespace in the Persistence store.

- [How to set the Retention Period for a Namespace](/tctl-v1/namespace#register)
- [How to set the Retention Period for a Namespace using the Go SDK](/dev-guide/go/features#namespaces) <span id="i-715a80cd-e5a5-44ed-9deb-8be561e6f0ec" class="clickable-i clickable-link-preview">ðŸ”—</span><div id="preview-modal-715a80cd-e5a5-44ed-9deb-8be561e6f0ec" class="preview-modal"><div class="modal-header"><div id="x-715a80cd-e5a5-44ed-9deb-8be561e6f0ec" class="clickable-x clickable-link-preview">x</div><b>Link preview</b></div><div class="preview-modal-title">How to create and manage Namespaces</div><div class="preview-modal-description">You can create, update, deprecate or delete your Namespaces using either tctl or SDK APIs..</div><div class="preview-modal-tags"><span class="preview-modal-tag">guide-context</span></div></div>
- [How to set the Retention Period for a Namespace using the Java SDK](/dev-guide/java/features#namespaces) <span id="i-9191e0de-340b-4dcd-9f49-6c2c79564c81" class="clickable-i clickable-link-preview">ðŸ”—</span><div id="preview-modal-9191e0de-340b-4dcd-9f49-6c2c79564c81" class="preview-modal"><div class="modal-header"><div id="x-9191e0de-340b-4dcd-9f49-6c2c79564c81" class="clickable-x clickable-link-preview">x</div><b>Link preview</b></div><div class="preview-modal-title">How to create and manage Namespaces</div><div class="preview-modal-description">You can create, update, deprecate or delete your Namespaces using either tctl or SDK APIs..</div><div class="preview-modal-tags"><span class="preview-modal-tag">guide-context</span></div></div>

A Retention Period applies to all closed Workflow Executions within a [Namespace](/namespaces#) <span id="i-3630ff8c-99af-4d47-8548-0fae7eb47320" class="clickable-i clickable-link-preview">ðŸ”—</span><div id="preview-modal-3630ff8c-99af-4d47-8548-0fae7eb47320" class="preview-modal"><div class="modal-header"><div id="x-3630ff8c-99af-4d47-8548-0fae7eb47320" class="clickable-x clickable-link-preview">x</div><b>Link preview</b></div><div class="preview-modal-title">What is a Namespace?</div><div class="preview-modal-description">A Namespace is a unit of isolation within the Temporal Platform</div><div class="preview-modal-tags"><span class="preview-modal-tag">term</span> <span class="preview-modal-tag">explanation</span></div></div> and is set when the Namespace is registered.

The Temporal Cluster triggers a Timer task at the end of the Retention Period that cleans up the data associated with the closed Workflow Execution on that Namespace.

The minimum Retention Period is 1 day.
On Temporal Cluster version 1.18 and later, the maximum Retention Period value for Namespaces can be set to anything over the minimum requirement of 1 day. Ensure that your Persistence store has enough capacity for the storage.
On Temporal Cluster versions 1.17 and earlier, the maximum Retention Period you can set is 30 days.
Setting the Retention Period to 0 results in the error _A valid retention period is not set on request_.

If you don't set the Retention Period value when using the [`tctl namespace register`](/tctl-v1/namespace#register) command, it defaults to 3 days.
If you don't set the Retention Period value when using the Register Namespace Request API, it returns an error.

When changing the Retention Period, the new duration applies to Workflow Executions that close after the change is saved.

<!-- TODO link up to working API usage examples -->

## What is Persistence? {#persistence}

The Temporal Persistence store is a database used by [Temporal Services](#temporal-server) <span id="i-7c0fde20-851b-430e-b6ce-bead949b75e6" class="clickable-i clickable-link-preview">ðŸ”—</span><div id="preview-modal-7c0fde20-851b-430e-b6ce-bead949b75e6" class="preview-modal"><div class="modal-header"><div id="x-7c0fde20-851b-430e-b6ce-bead949b75e6" class="clickable-x clickable-link-preview">x</div><b>Link preview</b></div><div class="preview-modal-title">What is the Temporal Server?</div><div class="preview-modal-description">The Temporal Server is a grouping of four horizontally scalable services.</div><div class="preview-modal-tags"><span class="preview-modal-tag">term</span> <span class="preview-modal-tag">explanation</span></div></div> to persist events generated and processed in your Temporal Cluster and SDK.

A Temporal Cluster's only required dependency for basic operation is the Persistence database.
Multiple types of databases are supported.

<div class="tdiw"><div class="tditw"><p class="tdit">Persistence</p></div><div class="tdiiw"><img class="img_ev3q" src="/diagrams/temporal-database.svg" alt="Persistence" height="620" width="1140" /></div></div>

The database stores the following types of data:

- Tasks: Tasks to be dispatched.
- State of Workflow Executions:
  - Execution table: A capture of the mutable state of Workflow Executions.
  - History table: An append-only log of Workflow Execution History Events.
- Namespace metadata: Metadata of each Namespace in the Cluster.
- [Visibility](#visibility) <span id="i-a6d6dde0-b2ad-4f78-b336-14096af1b2de" class="clickable-i clickable-link-preview">ðŸ”—</span><div id="preview-modal-a6d6dde0-b2ad-4f78-b336-14096af1b2de" class="preview-modal"><div class="modal-header"><div id="x-a6d6dde0-b2ad-4f78-b336-14096af1b2de" class="clickable-x clickable-link-preview">x</div><b>Link preview</b></div><div class="preview-modal-title">What is Visibility?</div><div class="preview-modal-description">The term Visibility, within the Temporal Platform, refers to the subsystems and APIs that enable an operator to view Workflow Executions that currently exist within a Cluster.</div><div class="preview-modal-tags"><span class="preview-modal-tag">term</span></div></div> data: Enables operations like "show all running Workflow Executions".
  For production environments, we recommend using Elasticsearch as your Visibility store.

An Elasticsearch database must be configured in a self-hosted Cluster to enable [advanced Visibility](/visibility#advanced-visibility) <span id="i-ff2a0d06-c75c-4bdd-b642-623dae85220d" class="clickable-i clickable-link-preview">ðŸ”—</span><div id="preview-modal-ff2a0d06-c75c-4bdd-b642-623dae85220d" class="preview-modal"><div class="modal-header"><div id="x-ff2a0d06-c75c-4bdd-b642-623dae85220d" class="clickable-x clickable-link-preview">x</div><b>Link preview</b></div><div class="preview-modal-title">What is advanced Visibility?</div><div class="preview-modal-description">Advanced Visibility, within the Temporal Platform, is the subsystem and APIs that enable the listing, filtering, and sorting of Workflow Executions through an SQL-like query syntax.</div><div class="preview-modal-tags"><span class="preview-modal-tag">explanation</span> <span class="preview-modal-tag">filtered-lists</span> <span class="preview-modal-tag">visibility</span></div></div> on Temporal Server versions 1.19.1 and earlier.

With Temporal Server version 1.20 and later, advanced Visibility features are available on SQL databases like MySQL (version 8.0.17 and later), PostgreSQL (version 12 and later), SQLite (v3.31.0 and later), and Elasticsearch.

#### Dependency versions

Temporal tests compatibility by spanning the minimum and maximum stable major versions for each supported database.
The following versions are used in our test pipelines and actively tested before we release any version of Temporal:

- **Cassandra v3.11 and v4.0**
- **PostgreSQL v10.18 and v13.4**
- **MySQL v5.7 and v8.0** (specifically 8.0.19+ due to a bug)

You can verify supported databases in the [Temporal Server release notes](https://github.com/temporalio/temporal/releases).

- Because Temporal Server primarily relies on core database functionality, we do not expect compatibility to break often.
  <!--Temporal has no opinions on database upgrade paths; as long as you can upgrade your database according to each project's specifications, Temporal should work with any version within supported ranges.-->
- We do not run tests with vendors like Vitess and CockroachDB.
- Temporal also supports SQLite v3.x persistence, but this is meant only for development and testing, not production usage.

## What is Visibility? {#visibility}

:::tip Support, stability, and dependency info

- For Temporal Server v1.19 and earlier, all supported databases for Visibility provide standard Visibility features, and an Elasticsearch database is required for advanced Visibility features.
- For Temporal Server v1.20 and later, advanced Visibility features are enabled on all supported SQL databases, in addition to Elasticsearch.
- In Temporal Server v1.21 and later, standard Visibility is no longer in development, and we recommend migrating to a [database that supports advanced Visibility features](/cluster-deployment-guide#supported-databases). Visibility configuration in Temporal Cluster is updated and Dual Visibility is enabled. For details, see [Visibility store setup](/cluster-deployment-guide#visibility-store).

:::

The term [Visibility](/visibility), within the Temporal Platform, refers to the subsystems and APIs that enable an operator to view, filter, and search for Workflow Executions that currently exist within a Cluster.

The [Visibility store](/cluster-deployment-guide#visibility-store) in your Temporal Cluster stores persisted Workflow Execution Event History data and is set up as a part of your [Persistence store](#persistence) <span id="i-5edd449c-40d5-467a-9ca6-b748f3dfb0c2" class="clickable-i clickable-link-preview">ðŸ”—</span><div id="preview-modal-5edd449c-40d5-467a-9ca6-b748f3dfb0c2" class="preview-modal"><div class="modal-header"><div id="x-5edd449c-40d5-467a-9ca6-b748f3dfb0c2" class="clickable-x clickable-link-preview">x</div><b>Link preview</b></div><div class="preview-modal-title">What is a Temporal Cluster?</div><div class="preview-modal-description">A Temporal Cluster is a Temporal Server paired with Persistence and Visibility stores.</div><div class="preview-modal-tags"><span class="preview-modal-tag">term</span> <span class="preview-modal-tag">explanation</span></div></div> to enable listing and filtering details about Workflow Executions that exist on your Temporal Cluster.

- [How to set up a Visibility store](/cluster-deployment-guide#visibility-store)

With Temporal Server v1.21, you can set up [Dual Visibility](/visibility#dual-visibility) <span id="i-44aa5154-3b94-4b38-808f-70ffbe04a0e4" class="clickable-i clickable-link-preview">ðŸ”—</span><div id="preview-modal-44aa5154-3b94-4b38-808f-70ffbe04a0e4" class="preview-modal"><div class="modal-header"><div id="x-44aa5154-3b94-4b38-808f-70ffbe04a0e4" class="clickable-x clickable-link-preview">x</div><b>Link preview</b></div><div class="preview-modal-title">What is Dual Visibility?</div><div class="preview-modal-description">Dual Visibility is a feature that lets you set a secondary Visibility store in your Temporal Cluster to facilitate migrating your Visibility data from one database to another.</div><div class="preview-modal-tags"><span class="preview-modal-tag">term</span> <span class="preview-modal-tag">explanation</span> <span class="preview-modal-tag">filtered-lists</span> <span class="preview-modal-tag">visibility</span></div></div> to migrate your Visibility store from one database to another.

<!-- A Visibility store can be configured to provide [atandard Visibility](/visibility#standard-visibility) and [advanced Visibility](/visibility#advanced-visibility) features.

Support for separate standard and advanced Visibility setups will be deprecated from Temporal Server v1.21 onwards. Check [Supported databases](/cluster-deployment-guide#supported-databases) for updates. -->

## What is Archival? {#archival}

Archival is a feature that automatically backs up [Event Histories](/workflows#event-history) <span id="i-69a2a5af-9e3f-4ebd-920d-6d9d8d4e61be" class="clickable-i clickable-link-preview">ðŸ”—</span><div id="preview-modal-69a2a5af-9e3f-4ebd-920d-6d9d8d4e61be" class="preview-modal"><div class="modal-header"><div id="x-69a2a5af-9e3f-4ebd-920d-6d9d8d4e61be" class="clickable-x clickable-link-preview">x</div><b>Link preview</b></div><div class="preview-modal-title">What is an Event History?</div><div class="preview-modal-description">An append-only log of Events that represents the full state a Workflow Execution.</div><div class="preview-modal-tags"><span class="preview-modal-tag">term</span> <span class="preview-modal-tag">explanation</span></div></div> and Visibility records from Temporal Cluster persistence to a custom blob store.

- [How to create a custom Archiver](/cluster-deployment-guide#custom-archiver) <span id="i-69be5cfd-747c-453e-887c-0c4846941cd8" class="clickable-i clickable-link-preview">ðŸ”—</span><div id="preview-modal-69be5cfd-747c-453e-887c-0c4846941cd8" class="preview-modal"><div class="modal-header"><div id="x-69be5cfd-747c-453e-887c-0c4846941cd8" class="clickable-x clickable-link-preview">x</div><b>Link preview</b></div><div class="preview-modal-title">How to create a custom Archiver</div><div class="preview-modal-description">To archive data with a given provider, using the Archival feature, Temporal must have a corresponding Archiver component installed.</div><div class="preview-modal-tags"><span class="preview-modal-tag">how-to</span></div></div>
- [How to set up Archival](/cluster-deployment-guide#set-up-archival) <span id="i-c1ad73f9-3b89-4348-b8ed-7abc8401aef4" class="clickable-i clickable-link-preview">ðŸ”—</span><div id="preview-modal-c1ad73f9-3b89-4348-b8ed-7abc8401aef4" class="preview-modal"><div class="modal-header"><div id="x-c1ad73f9-3b89-4348-b8ed-7abc8401aef4" class="clickable-x clickable-link-preview">x</div><b>Link preview</b></div><div class="preview-modal-title">How to set up Archival</div><div class="preview-modal-description">This guide covers Temporal's archiving capabilities and how to set up the Archival feature.</div><div class="preview-modal-tags"><span class="preview-modal-tag">how-to</span></div></div>

Workflow Execution Event Histories are backed up after the [Retention Period](/namespaces#retention-period) <span id="i-103e174f-39b5-4726-b004-0ac5889ae381" class="clickable-i clickable-link-preview">ðŸ”—</span><div id="preview-modal-103e174f-39b5-4726-b004-0ac5889ae381" class="preview-modal"><div class="modal-header"><div id="x-103e174f-39b5-4726-b004-0ac5889ae381" class="clickable-x clickable-link-preview">x</div><b>Link preview</b></div><div class="preview-modal-title">What is a Namespace?</div><div class="preview-modal-description">A Namespace is a unit of isolation within the Temporal Platform</div><div class="preview-modal-tags"><span class="preview-modal-tag">term</span> <span class="preview-modal-tag">explanation</span></div></div> is reached.
Visibility records are backed up immediately after a Workflow Execution reaches a Closed status.

Archival enables Workflow Execution data to persist as long as needed, while not overwhelming the Cluster's persistence store.

This feature is helpful for compliance and debugging.

Temporal's Archival feature is considered **experimental** and not subject to normal [versioning and support policy](/clusters).

Archival is not supported when running Temporal through Docker and is disabled by default when installing the system manually and when deploying through [helm charts](https://github.com/temporalio/helm-charts/blob/master/templates/server-configmap.yaml) (but can be enabled in the [config](https://github.com/temporalio/temporal/blob/master/config/development.yaml)).

## What is Cluster configuration? {#cluster-configuration}

Cluster configuration is the setup and configuration details of your self-hosted Temporal Cluster, defined using YAML.
You must define your Cluster configuration when setting up your self-hosted Temporal Cluster.

For details on using Temporal Cloud, see [Temporal Cloud documentation](/cloud).

Cluster configuration is composed of two types of configuration: [Static configuration](#static-configuration) and [Dynamic configuration](#dynamic-configuration).

### Static configuration

Static configuration contains details of how the Cluster should be set up.
The static configuration is read just once and used to configure service nodes at startup.
Depending on how you want to deploy your self-hosted Temporal Cluster, your static configuration must contain details for setting up:

- Temporal Servicesâ€”Frontend, History, Matching, Worker
- Membership ports for the Temporal Services
- Persistence (including History Shard count), Visibility, Archival store setups.
- TLS, authentication, authorization
- Server log level
- Metrics
- Cluster metadata
- Dynamic config Client

Static configuration values cannot be changed at runtime.
Some values, such as the Metrics configuration or Server log level can be changed in the static configuration but require restarting the Cluster for the changes to take effect.

For details on static configuration keys, see [Cluster configuration reference](/references/configuration#) <span id="i-8f192b59-f149-4d89-b07f-d1e95a3288ef" class="clickable-i clickable-link-preview">ðŸ”—</span><div id="preview-modal-8f192b59-f149-4d89-b07f-d1e95a3288ef" class="preview-modal"><div class="modal-header"><div id="x-8f192b59-f149-4d89-b07f-d1e95a3288ef" class="clickable-x clickable-link-preview">x</div><b>Link preview</b></div><div class="preview-modal-title">Temporal Cluster configuration reference</div><div class="preview-modal-description">Much of the behavior of a Temporal Cluster is configured using the `development.yaml` file.</div><div class="preview-modal-tags"><span class="preview-modal-tag">reference</span></div></div>.

For static configuration examples, see <https://github.com/temporalio/temporal/tree/master/config>.

### Dynamic configuration

Dynamic configuration contains configuration keys that you can update in your Cluster setup without having to restart the server processes.

All dynamic configuration keys provided by Temporal have default values that are used by the Cluster.
You can override the default values by setting different values for the keys in a YAML file and setting the [dynamic configuration client](/references/configuration#dynamicconfigclient) <span id="i-3147dd55-cb5a-4edc-a24f-2e152e051c86" class="clickable-i clickable-link-preview">ðŸ”—</span><div id="preview-modal-3147dd55-cb5a-4edc-a24f-2e152e051c86" class="preview-modal"><div class="modal-header"><div id="x-3147dd55-cb5a-4edc-a24f-2e152e051c86" class="clickable-x clickable-link-preview">x</div><b>Link preview</b></div><div class="preview-modal-title">Temporal Cluster configuration reference</div><div class="preview-modal-description">Much of the behavior of a Temporal Cluster is configured using the `development.yaml` file.</div><div class="preview-modal-tags"><span class="preview-modal-tag">reference</span></div></div> to poll this file for updates.
Setting dynamic configuration for your Cluster is optional.

Setting overrides for some configuration keys updates the Cluster configuration immediately.
However, for configuration fields that are checked at startup (such as thread pool size), you must restart the server for the changes to take effect.

Use dynamic configuration keys to fine-tune your self-deployed Cluster setup.

For details on dynamic configuration keys, see [Dynamic configuration reference](/references/dynamic-configuration#) <span id="i-a2caf7af-b696-471f-af5c-9ee963cbaf8e" class="clickable-i clickable-link-preview">ðŸ”—</span><div id="preview-modal-a2caf7af-b696-471f-af5c-9ee963cbaf8e" class="preview-modal"><div class="modal-header"><div id="x-a2caf7af-b696-471f-af5c-9ee963cbaf8e" class="clickable-x clickable-link-preview">x</div><b>Link preview</b></div><div class="preview-modal-title">Dynamic configuration reference</div><div class="preview-modal-description">Dynamic configuration key values can be set to override the default values in a Cluster configuration.</div><div class="preview-modal-tags"><span class="preview-modal-tag">reference</span></div></div>.

For dynamic configuration examples, see <https://github.com/temporalio/temporal/tree/master/config/dynamicconfig>.

### What is Cluster security configuration? {#temporal-cluster-security-configuration}

Secure your Temporal Cluster (self-hosted and Temporal Cloud) by encrypting your network communication and setting authentication and authorization protocols for API calls.

For details on setting up your Temporal Cluster security, see [Temporal Platform security features](/security).

#### mTLS encryption

Temporal supports Mutual Transport Layer Security (mTLS) to encrypt network traffic between services within a Temporal Cluster, or between application processes and a Cluster.

On self-hosted Temporal Clusters, configure mTLS in the `tls` section of the [Cluster configuration](/references/configuration#tls) <span id="i-b8a0f4cf-22d2-43c0-8f8f-ec5b6180893d" class="clickable-i clickable-link-preview">ðŸ”—</span><div id="preview-modal-b8a0f4cf-22d2-43c0-8f8f-ec5b6180893d" class="preview-modal"><div class="modal-header"><div id="x-b8a0f4cf-22d2-43c0-8f8f-ec5b6180893d" class="clickable-x clickable-link-preview">x</div><b>Link preview</b></div><div class="preview-modal-title">Temporal Cluster configuration reference</div><div class="preview-modal-description">Much of the behavior of a Temporal Cluster is configured using the `development.yaml` file.</div><div class="preview-modal-tags"><span class="preview-modal-tag">reference</span></div></div>.
mTLS configuration is a [static configuration](#static-configuration) property.

You can then use either the [`WithConfig`](/references/server-options#withconfig) <span id="i-52d6cfd4-e9bf-480f-af3a-f2d83f529349" class="clickable-i clickable-link-preview">ðŸ”—</span><div id="preview-modal-52d6cfd4-e9bf-480f-af3a-f2d83f529349" class="preview-modal"><div class="modal-header"><div id="x-52d6cfd4-e9bf-480f-af3a-f2d83f529349" class="clickable-x clickable-link-preview">x</div><b>Link preview</b></div><div class="preview-modal-title">Temporal Server options</div><div class="preview-modal-description">You can run the Temporal Server as a Go application by including the server package `go.temporal.io/server/temporal` and using it to create and start a Temporal Server.</div><div class="preview-modal-tags"><span class="preview-modal-tag">reference</span> <span class="preview-modal-tag">web-ui</span></div></div> or [`WithConfigLoader`](/references/server-options#withconfigloader) <span id="i-cd1bba17-57bb-4363-b6ff-92224cc9a7d1" class="clickable-i clickable-link-preview">ðŸ”—</span><div id="preview-modal-cd1bba17-57bb-4363-b6ff-92224cc9a7d1" class="preview-modal"><div class="modal-header"><div id="x-cd1bba17-57bb-4363-b6ff-92224cc9a7d1" class="clickable-x clickable-link-preview">x</div><b>Link preview</b></div><div class="preview-modal-title">Temporal Server options</div><div class="preview-modal-description">You can run the Temporal Server as a Go application by including the server package `go.temporal.io/server/temporal` and using it to create and start a Temporal Server.</div><div class="preview-modal-tags"><span class="preview-modal-tag">reference</span> <span class="preview-modal-tag">web-ui</span></div></div> server option to start your Temporal Cluster with this configuration.

The mTLS configuration includes two sections that serve to separate communication within a Temporal Cluster and client calls made from your application to the Cluster.

- `internode`: configuration for encrypting communication between nodes within the Cluster.
- `frontend`: configuration for encrypting the public endpoints of the Frontend Service.

Setting mTLS for `internode` and `frontend` separately lets you use different certificates and settings to encrypt each section of traffic.

#### Using certificates for Client connections

Use CA certificates to authenticate client connections to your Temporal Cluster.

On Temporal Cloud, you can [set your CA certificates in your Temporal Cloud settings](/cloud/account-setup/certificates#) <span id="i-f97af87e-4c90-41ad-86e6-702a8797ec29" class="clickable-i clickable-link-preview">ðŸ”—</span><div id="preview-modal-f97af87e-4c90-41ad-86e6-702a8797ec29" class="preview-modal"><div class="modal-header"><div id="x-f97af87e-4c90-41ad-86e6-702a8797ec29" class="clickable-x clickable-link-preview">x</div><b>Link preview</b></div><div class="preview-modal-title">How to manage certificates in Temporal Cloud</div><div class="preview-modal-description">Certificates needed for Temporal Cloud and Worker Processes</div><div class="preview-modal-tags"><span class="preview-modal-tag">introduction</span> <span class="preview-modal-tag">temporal cloud</span> <span class="preview-modal-tag">certificates</span></div></div> and use the end-entity certificates in your client calls.

On self-hosted Temporal Clusters, you can restrict access to Temporal Cluster endpoints by using the `clientCAFiles` or `clientCAData` property and the [`requireClientAuth`](/references/configuration#tls) <span id="i-637e2152-ea19-4c3a-8331-7286038093a2" class="clickable-i clickable-link-preview">ðŸ”—</span><div id="preview-modal-637e2152-ea19-4c3a-8331-7286038093a2" class="preview-modal"><div class="modal-header"><div id="x-637e2152-ea19-4c3a-8331-7286038093a2" class="clickable-x clickable-link-preview">x</div><b>Link preview</b></div><div class="preview-modal-title">Temporal Cluster configuration reference</div><div class="preview-modal-description">Much of the behavior of a Temporal Cluster is configured using the `development.yaml` file.</div><div class="preview-modal-tags"><span class="preview-modal-tag">reference</span></div></div> property in your Cluster configuration.
These properties can be specified in both the `internode` and `frontend` sections of the [mTLS configuration](/references/configuration#tls) <span id="i-ad4e8479-248f-43dd-ba32-41a15d198874" class="clickable-i clickable-link-preview">ðŸ”—</span><div id="preview-modal-ad4e8479-248f-43dd-ba32-41a15d198874" class="preview-modal"><div class="modal-header"><div id="x-ad4e8479-248f-43dd-ba32-41a15d198874" class="clickable-x clickable-link-preview">x</div><b>Link preview</b></div><div class="preview-modal-title">Temporal Cluster configuration reference</div><div class="preview-modal-description">Much of the behavior of a Temporal Cluster is configured using the `development.yaml` file.</div><div class="preview-modal-tags"><span class="preview-modal-tag">reference</span></div></div>.
For details, see the [tls configuration reference](/references/configuration#tls) <span id="i-28e59692-a601-4776-9780-942740742f73" class="clickable-i clickable-link-preview">ðŸ”—</span><div id="preview-modal-28e59692-a601-4776-9780-942740742f73" class="preview-modal"><div class="modal-header"><div id="x-28e59692-a601-4776-9780-942740742f73" class="clickable-x clickable-link-preview">x</div><b>Link preview</b></div><div class="preview-modal-title">Temporal Cluster configuration reference</div><div class="preview-modal-description">Much of the behavior of a Temporal Cluster is configured using the `development.yaml` file.</div><div class="preview-modal-tags"><span class="preview-modal-tag">reference</span></div></div>.

#### Server name specification

On self-hosted Temporal Clusters, you can specify `serverName` in the `client` section of your mTLS configuration to prevent spoofing and [MITM attacks](https://en.wikipedia.org/wiki/Man-in-the-middle_attack).

Entering a value for `serverName` enables established connections to authenticate the endpoint.
This ensures that the server certificate presented to any connected client has the specified server name in its CN property.

This measure can be used for `internode` and `frontend` endpoints.

For more information on mTLS configuration, see [tls configuration reference](/references/configuration#tls) <span id="i-ed1bf9a6-15ca-4158-9b8a-50cca0b3055e" class="clickable-i clickable-link-preview">ðŸ”—</span><div id="preview-modal-ed1bf9a6-15ca-4158-9b8a-50cca0b3055e" class="preview-modal"><div class="modal-header"><div id="x-ed1bf9a6-15ca-4158-9b8a-50cca0b3055e" class="clickable-x clickable-link-preview">x</div><b>Link preview</b></div><div class="preview-modal-title">Temporal Cluster configuration reference</div><div class="preview-modal-description">Much of the behavior of a Temporal Cluster is configured using the `development.yaml` file.</div><div class="preview-modal-tags"><span class="preview-modal-tag">reference</span></div></div>.

#### Authentication and authorization

<!-- commenting this very generic explanation out. Can include it back in if everyone feels strongly.
 **Authentication** is the process of verifying users who want to access your application are actually the users you want accessing it.
**Authorization** is the verification of applications and data that a user on your Cluster or application has access to. -->

Temporal provides authentication interfaces that can be set to restrict access to your data.
These protocols address three areas: servers, client connections, and users.

Temporal offers two plugin interfaces for authentication and authorization of API calls.

- [`ClaimMapper`](/security#claim-mapper) <span id="i-af38f5ff-439f-45d9-a47e-105d7d56ceb7" class="clickable-i clickable-link-preview">ðŸ”—</span><div id="preview-modal-af38f5ff-439f-45d9-a47e-105d7d56ceb7" class="preview-modal"><div class="modal-header"><div id="x-af38f5ff-439f-45d9-a47e-105d7d56ceb7" class="clickable-x clickable-link-preview">x</div><b>Link preview</b></div><div class="preview-modal-title">What is a ClaimMapper Plugin?</div><div class="preview-modal-description">The Claim Mapper component is a pluggable component that extracts Claims from JSON Web Tokens (JWTs).</div><div class="preview-modal-tags"><span class="preview-modal-tag">term</span></div></div>
- [`Authorizer`](/security#authorizer-plugin) <span id="i-1bd79034-008d-4ed6-a536-b0bc9f52e625" class="clickable-i clickable-link-preview">ðŸ”—</span><div id="preview-modal-1bd79034-008d-4ed6-a536-b0bc9f52e625" class="preview-modal"><div class="modal-header"><div id="x-1bd79034-008d-4ed6-a536-b0bc9f52e625" class="clickable-x clickable-link-preview">x</div><b>Link preview</b></div><div class="preview-modal-title">What is an Authorizer Plugin?</div><div class="preview-modal-description">undefined</div><div class="preview-modal-tags"><span class="preview-modal-tag">term</span></div></div>

The logic of both plugins can be customized to fit a variety of use cases.
When plugins are provided, the Frontend Service invokes their implementation before running the requested operation.

### What is Cluster observability? {#monitoring-and-observation}

You can monitor and observe performance with metrics emitted by your self-hosted Temporal Cluster or by Temporal Cloud.

Temporal emits metrics by default in a format that is supported by Prometheus.
Any metrics software that supports the same format can be used.
Currently, we test with the following Prometheus and Grafana versions:

- **Prometheus >= v2.0**
- **Grafana >= v2.5**

Temporal Cloud emits metrics through a Prometheus HTTP API endpoint, which can be directly used as a Prometheus data source in Grafana or to query and export Cloud metrics to any observability platform.

For details on Cloud metrics and setup, see the following:

- [Temporal Cloud metrics reference](/cloud/metrics#) <span id="i-1f09c87c-99d3-43d5-b168-9f26451abe4a" class="clickable-i clickable-link-preview">ðŸ”—</span><div id="preview-modal-1f09c87c-99d3-43d5-b168-9f26451abe4a" class="preview-modal"><div class="modal-header"><div id="x-1f09c87c-99d3-43d5-b168-9f26451abe4a" class="clickable-x clickable-link-preview">x</div><b>Link preview</b></div><div class="preview-modal-title">How to monitor Temporal Cloud metrics</div><div class="preview-modal-description">Configure and track performance metrics for Temporal Cloud.</div><div class="preview-modal-tags"><span class="preview-modal-tag">introduction</span> <span class="preview-modal-tag">temporal cloud</span> <span class="preview-modal-tag">metrics</span></div></div>
- [Set up Grafana with Temporal Cloud observability to view metrics](/cloud/metrics#data-sources-configuration-for-temporal-cloud-and-sdk-metrics-in-grafana) <span id="i-6c4b3f18-c47c-455b-bc9d-f2b855dca54d" class="clickable-i clickable-link-preview">ðŸ”—</span><div id="preview-modal-6c4b3f18-c47c-455b-bc9d-f2b855dca54d" class="preview-modal"><div class="modal-header"><div id="x-6c4b3f18-c47c-455b-bc9d-f2b855dca54d" class="clickable-x clickable-link-preview">x</div><b>Link preview</b></div><div class="preview-modal-title">How to set up Grafana with Temporal Cloud observability to view metrics</div><div class="preview-modal-description">Temporal Cloud and SDKs generate metrics for monitoring performance and troubleshooting errors.</div><div class="preview-modal-tags"><span class="preview-modal-tag">how-to</span> <span class="preview-modal-tag">grafana</span> <span class="preview-modal-tag">temporal cloud</span> <span class="preview-modal-tag">observability</span></div></div>

On self-hosted Temporal Clusters, expose Prometheus endpoints in your Cluster configuration and configure Prometheus to scrape metrics from the endpoints.
You can then set up your observability platform (such as Grafana) to use Prometheus as a data source.

For details on self-hosted Cluster metrics and setup, see the following:

- [Temporal Cluster OSS metrics reference](/references/cluster-metrics#) <span id="i-0600237d-114a-448c-b274-81c3175bea9e" class="clickable-i clickable-link-preview">ðŸ”—</span><div id="preview-modal-0600237d-114a-448c-b274-81c3175bea9e" class="preview-modal"><div class="modal-header"><div id="x-0600237d-114a-448c-b274-81c3175bea9e" class="clickable-x clickable-link-preview">x</div><b>Link preview</b></div><div class="preview-modal-title">Temporal OSS Cluster metrics reference</div><div class="preview-modal-description">The Temporal Cluster emits a range of metrics to help operators get visibility into the Clusterâ€™s performance and set up alerts.</div><div class="preview-modal-tags"><span class="preview-modal-tag">reference</span></div></div>
- [Set up Prometheus and Grafana to view SDK and self-hosted Cluster metrics](/kb/prometheus-grafana-setup)

## What is Multi-Cluster Replication? {#multi-cluster-replication}

Multi-Cluster Replication is a feature which asynchronously replicates Workflow Executions from active Clusters to other passive Clusters, for backup and state reconstruction.
When necessary, for higher availability, Cluster operators can failover to any of the backup Clusters.

Temporal's Multi-Cluster Replication feature is considered **experimental** and not subject to normal [versioning and support policy](/clusters).

Temporal automatically forwards Start, Signal, and Query requests to the active Cluster.
This feature must be enabled through a Dynamic Config flag per [Global Namespace](/namespaces#global-namespace) <span id="i-7bda480c-1254-4cbd-9124-a385db143543" class="clickable-i clickable-link-preview">ðŸ”—</span><div id="preview-modal-7bda480c-1254-4cbd-9124-a385db143543" class="preview-modal"><div class="modal-header"><div id="x-7bda480c-1254-4cbd-9124-a385db143543" class="clickable-x clickable-link-preview">x</div><b>Link preview</b></div><div class="preview-modal-title">What is a Global Namespace?</div><div class="preview-modal-description">A Global Namespace is a Namespace that exists across Clusters when Multi-Cluster Replication is set up.</div><div class="preview-modal-tags"><span class="preview-modal-tag">term</span> <span class="preview-modal-tag">explanation</span></div></div>.

When the feature is enabled, Tasks are sent to the Parent Task Queue partition that matches that Namespace, if it exists.

All Visibility APIs can be used against active and standby Clusters.
This enables [Temporal UI](https://docs.temporal.io/web-ui) to work seamlessly for Global Namespaces.
Applications making API calls directly to the Temporal Visibility API continue to work even if a Global Namespace is in standby mode.
However, they might see a lag due to replication delay when querying the Workflow Execution state from a standby Cluster.

#### Namespace Versions

A _version_ is a concept in Multi-Cluster Replication that describes the chronological order of events per Namespace.

With Multi-Cluster Replication, all Namespace change events and Workflow Execution History events are replicated asynchronously for high throughput.
This means that data across clusters is **not** strongly consistent.
To guarantee that Namespace data and Workflow Execution data will achieve eventual consistency (especially when there is a data conflict during a failover), a **version** is introduced and attached to Namespaces.
All Workflow Execution History entries generated in a Namespace will also come with the version attached to that Namespace.

All participating Clusters are pre-configured with a unique initial version and a shared version increment:

- `initial version < shared version increment`

When performing failover for a Namespace from one Cluster to another Cluster, the version attached to the Namespace will be changed by the following rule:

- for all versions which follow `version % (shared version increment) == (active cluster's initial version)`, find the smallest version which has `version >= old version in namespace`

When there is a data conflict, a comparison will be made and Workflow Execution History entries with the highest version will be considered the source of truth.

When a cluster is trying to mutate a Workflow Execution History, the version will be checked.
A cluster can mutate a Workflow Execution History only if the following is true:

- The version in the Namespace belongs to this cluster, i.e.
  `(version in namespace) % (shared version increment) == (this cluster's initial version)`
- The version of this Workflow Execution History's last entry (event) is equal or less than the version in the Namespace, i.e.
  `(last event's version) <= (version in namespace)`

<details>
<summary>Namespace version change example
</summary>

Assuming the following scenario:

- Cluster A comes with initial version: 1
- Cluster B comes with initial version: 2
- Shared version increment: 10

T = 0: Namespace Î± is registered, with active Cluster set to Cluster A

```
namespace Î±'s version is 1
all workflows events generated within this namespace, will come with version 1
```

T = 1: namespace Î² is registered, with active Cluster set to Cluster B

```
namespace Î²'s version is 2
all workflows events generated within this namespace, will come with version 2
```

T = 2: Namespace Î± is updated to with active Cluster set to Cluster B

```
namespace Î±'s version is 2
all workflows events generated within this namespace, will come with version 2
```

T = 3: Namespace Î² is updated to with active Cluster set to Cluster A

```
namespace Î²'s version is 11
all workflows events generated within this namespace, will come with version 11
```

</details>

#### Version history

Version history is a concept which provides a high level summary of version information in regards to Workflow Execution History.

Whenever there is a new Workflow Execution History entry generated, the version from Namespace will be attached.
The Workflow Executions's mutable state will keep track of all history entries (events) and the corresponding version.

<details>
<summary>Version history example (without data conflict)
</summary>

- Cluster A comes with initial version: 1
- Cluster B comes with initial version: 2
- Shared version increment: 10

T = 0: adding event with event ID == 1 & version == 1

View in both Cluster A & B

```
| -------- | ------------- | --------------- | ------- |
| Events   | Version History |
| -------- | --------------- | --------------- | ------- |
| Event ID | Event Version   | Event ID        | Version |
| -------- | -------------   | --------------- | ------- |
| 1        | 1               | 1               | 1       |
| -------- | -------------   | --------------- | ------- |
```

T = 1: adding event with event ID == 2 & version == 1

View in both Cluster A & B

```
| -------- | ------------- | --------------- | ------- |
| Events   | Version History |
| -------- | --------------- | --------------- | ------- |
| Event ID | Event Version   | Event ID        | Version |
| -------- | -------------   | --------------- | ------- |
| 1        | 1               | 2               | 1       |
| 2        | 1               |                 |         |
| -------- | -------------   | --------------- | ------- |
```

T = 2: adding event with event ID == 3 & version == 1

View in both Cluster A & B

```
| -------- | ------------- | --------------- | ------- |
| Events   | Version History |
| -------- | --------------- | --------------- | ------- |
| Event ID | Event Version   | Event ID        | Version |
| -------- | -------------   | --------------- | ------- |
| 1        | 1               | 3               | 1       |
| 2        | 1               |                 |         |
| 3        | 1               |                 |         |
| -------- | -------------   | --------------- | ------- |
```

T = 3: Namespace failover triggered, Namespace version is now 2
adding event with event ID == 4 & version == 2

View in both Cluster A & B

```
| -------- | ------------- | --------------- | ------- |
| Events   | Version History |
| -------- | --------------- | --------------- | ------- |
| Event ID | Event Version   | Event ID        | Version |
| -------- | -------------   | --------------- | ------- |
| 1        | 1               | 3               | 1       |
| 2        | 1               | 4               | 2       |
| 3        | 1               |                 |         |
| 4        | 2               |                 |         |
| -------- | -------------   | --------------- | ------- |
```

T = 4: adding event with event ID == 5 & version == 2

View in both Cluster A & B

```
| -------- | ------------- | --------------- | ------- |
| Events   | Version History |
| -------- | --------------- | --------------- | ------- |
| Event ID | Event Version   | Event ID        | Version |
| -------- | -------------   | --------------- | ------- |
| 1        | 1               | 3               | 1       |
| 2        | 1               | 5               | 2       |
| 3        | 1               |                 |         |
| 4        | 2               |                 |         |
| 5        | 2               |                 |         |
| -------- | -------------   | --------------- | ------- |
```

</details>

Since Temporal is AP, during failover (change of active Temporal Cluster Namespace), there can exist cases where more than one Cluster can modify a Workflow Execution, causing divergence of Workflow Execution History. Below shows how the version history will look like under such conditions.

<details>
<summary>Version history example (with data conflict)
</summary>

Below, shows version history of the same Workflow Execution in 2 different Clusters.

- Cluster A comes with initial version: 1
- Cluster B comes with initial version: 2
- Cluster C comes with initial version: 3
- Shared version increment: 10

T = 0:

View in both Cluster B & C

```
| -------- | ------------- | --------------- | ------- |
| Events   | Version History |
| -------- | --------------- | --------------- | ------- |
| Event ID | Event Version   | Event ID        | Version |
| -------- | -------------   | --------------- | ------- |
| 1        | 1               | 2               | 1       |
| 2        | 1               | 3               | 2       |
| 3        | 2               |                 |         |
| -------- | -------------   | --------------- | ------- |
```

T = 1: adding event with event ID == 4 & version == 2 in Cluster B

```
| -------- | ------------- | --------------- | ------- |
| Events   | Version History |
| -------- | --------------- | --------------- | ------- |
| Event ID | Event Version   | Event ID        | Version |
| -------- | -------------   | --------------- | ------- |
| 1        | 1               | 2               | 1       |
| 2        | 1               | 4               | 2       |
| 3        | 2               |                 |         |
| 4        | 2               |                 |         |
| -------- | -------------   | --------------- | ------- |
```

T = 1: namespace failover to Cluster C, adding event with event ID == 4 & version == 3 in Cluster C

```
| -------- | ------------- | --------------- | ------- |
| Events   | Version History |
| -------- | --------------- | --------------- | ------- |
| Event ID | Event Version   | Event ID        | Version |
| -------- | -------------   | --------------- | ------- |
| 1        | 1               | 2               | 1       |
| 2        | 1               | 3               | 2       |
| 3        | 2               | 4               | 3       |
| 4        | 3               |                 |         |
| -------- | -------------   | --------------- | ------- |
```

T = 2: replication task from Cluster C arrives in Cluster B

Note: below are a tree structures

```
                | -------- | ------------- |
                | Events        |
                | ------------- | ------------- |
                | Event ID      | Event Version |
                | --------      | ------------- |
                | 1             | 1             |
                | 2             | 1             |
                | 3             | 2             |
                | --------      | ------------- |
                |               |
                | ------------- | ------------  |
                |               |
                | --------      | ------------- |  | -------- | ------------- |
                | Event ID      | Event Version |  | Event ID | Event Version |
                | --------      | ------------- |  | -------- | ------------- |
                | 4             | 2             |  | 4        | 3             |
                | --------      | ------------- |  | -------- | ------------- |

          | --------------- | ------- |
          | Version History |
          | --------------- | ------------------- |
          | Event ID        | Version             |
          | --------------- | -------             |
          | 2               | 1                   |
          | 3               | 2                   |
          | --------------- | -------             |
          |                 |
          | -------         | ------------------- |
          |                 |
          | --------------- | -------             |  | --------------- | ------- |
          | Event ID        | Version             |  | Event ID        | Version |
          | --------------- | -------             |  | --------------- | ------- |
          | 4               | 2                   |  | 4               | 3       |
          | --------------- | -------             |  | --------------- | ------- |
```

T = 2: replication task from Cluster B arrives in Cluster C, same as above

</details>

#### Conflict resolution

When a Workflow Execution History diverges, proper conflict resolution is applied.

In Multi-cluster Replication, Workflow Execution History Events are modeled as a tree, as shown in the second example in [Version History](#version-history).

Workflow Execution Histories that diverge will have more than one history branch.
Among all history branches, the history branch with the highest version is considered the `current branch` and the Workflow Execution's mutable state is a summary of the current branch.
Whenever there is a switch between Workflow Execution History branches, a complete rebuild of the Workflow Execution's mutable state will occur.

Temporal Multi-Cluster Replication relies on asynchronous replication of Events across Clusters, so in the case of a failover it is possible to have an Activity Task dispatched again to the newly active Cluster due to a replication task lag.
This also means that whenever a Workflow Execution is updated after a failover by the new Cluster, any previous replication tasks for that Execution cannot be applied.
This results in loss of some progress made by the Workflow Execution in the previous active Cluster.
During such conflict resolution, Temporal re-injects any external Events like Signals in the new Event History before discarding replication tasks.
Even though some progress could roll back during failovers, Temporal provides the guarantee that Workflow Executions wonâ€™t get stuck and will continue to make forward progress.

Activity Execution completions are not forwarded across Clusters.
Any outstanding Activities will eventually time out based on the configuration.
Your application should have retry logic in place so that the Activity gets retried and dispatched again to a Worker after the failover to the new Cluster.
Handling this is similar to handling an Activity Task timeout caused by a Worker restarting.

#### Zombie Workflows

There is an existing contract that for any Namespace and Workflow Id combination, there can be at most one run (Namespace + Workflow Id + Run Id) open / executing.

Multi-cluster Replication aims to keep the Workflow Execution History as up-to-date as possible among all participating Clusters.

Due to the nature of Multi-cluster Replication (for example, Workflow Execution History events are replicated asynchronously) different Runs (same Namespace and Workflow Id) can arrive at the target Cluster at different times, sometimes out of order, as shown below:

```
| ------------- |          | ------------- |          | ------------- |
| Cluster A |  | Network Layer |  | Cluster B |
| --------- || ------------- |          | ------------- |
        |                          |                          |
        | Run 1 Replication Events |                          |
        | -----------------------> |                          |
        |                          |                          |
        | Run 2 Replication Events |                          |
        | -----------------------> |                          |
        |                          |                          |
        |                          |                          |
        |                          |                          |
        |                          | Run 2 Replication Events |
        |                          | -----------------------> |
        |                          |                          |
        |                          | Run 1 Replication Events |
        |                          | -----------------------> |
        |     |  |
        | --- || ------------- |          | ------------- |
| Cluster A |  | Network Layer |  | Cluster B |
| --------- || ------------- |          | ------------- |
```

Because Run 2 appears in Cluster B first, Run 1 cannot be replicated as "runnable" due to the rule `at most one Run open` (see above), thus the "zombie" Workflow Execution state is introduced.
A "zombie" state is one in which a Workflow Execution which cannot be actively mutated by a Cluster (assuming the corresponding Namespace is active in this Cluster). A zombie Workflow Execution can only be changed by a replication Task.

Run 1 will be replicated similar to Run 2, except when Run 1's execution will become a "zombie" before Run 1 reaches completion.

#### Workflow Task processing

In the context of Multi-cluster Replication, a Workflow Execution's mutable state is an entity which tracks all pending tasks.
Prior to the introduction of Multi-cluster Replication, Workflow Execution History entries (events) are from a single branch, and the Temporal Server will only append new entries (events) to the Workflow Execution History.

After the introduction of Multi-cluster Replication, it is possible that a Workflow Execution can have multiple Workflow Execution History branches.
Tasks generated according to one history branch may become invalidated by switching history branches during conflict resolution.

Example:

T = 0: task A is generated according to Event Id: 4, version: 2

```
| -------- | ------------- |
| Events   |
| -------- | ------------- |
| Event ID | Event Version |
| -------- | ------------- |
| 1        | 1             |
| 2        | 1             |
| 3        | 2             |
| -------- | ------------- |
|          |
|          |
| -------- | ------------- |
| Event ID | Event Version |
| -------- | ------------- |
| 4        | 2             | <-- task A belongs to this event |
| -------- | ------------- |
```

T = 1: conflict resolution happens, Workflow Execution's mutable state is rebuilt and history Event Id: 4, version: 3 is written down to persistence

```
| -------- | ------------- |
| Events        |
| ------------- | -------------------------------------------- |
| Event ID      | Event Version                                |
| --------      | -------------                                |
| 1             | 1                                            |
| 2             | 1                                            |
| 3             | 2                                            |
| --------      | -------------                                |
|               |
| ------------- | -------------------------------------------- |
|               |
| --------      | -------------                                |                                  | -------- | ------------- |
| Event ID      | Event Version                                |                                  | Event ID | Event Version |
| --------      | -------------                                |                                  | -------- | ------------- |
| 4             | 2                                            | <-- task A belongs to this event | 4        | 3             | <-- current branch / mutable state |
| --------      | -------------                                |                                  | -------- | ------------- |
```

T = 2: task A is loaded.

At this time, due to the rebuild of a Workflow Execution's mutable state (conflict resolution), Task A is no longer relevant (Task A's corresponding Event belongs to non-current branch).
Task processing logic will verify both the Event Id and version of the Task against a corresponding Workflow Execution's mutable state, then discard task A.
